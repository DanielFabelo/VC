{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import csv\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "model1 = YOLO('C:/Users/danif/Downloads/best_vc.pt')\n",
    "\n",
    "model2 = YOLO('yolo11n.pt')\n",
    "\n",
    "# Liste di classi per ciascun modello\n",
    "classNames_model1 = [\"matricula\"]\n",
    "classNames_model2 = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Cattura video\n",
    "vid = cv2.VideoCapture('C:/Users/danif/Downloads/C0142.MP4')\n",
    "\n",
    "plates_images = []\n",
    "\n",
    "while True:\n",
    "    ret, img = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Rilevamento con il primo modello\n",
    "    results1 = model1(img, stream=True)\n",
    "    for r in results1:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls < len(classNames_model1):\n",
    "                class_name = classNames_model1[cls]\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = round(float(box.conf[0]) * 100, 2)\n",
    "\n",
    "                #ritaglio l'immagine della targa\n",
    "                plate_image = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Aggiungi l'immagine della targa alla lista\n",
    "                plates_images.append(plate_image)\n",
    "\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(img, f'{class_name} {confidence}%', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    # Rilevamento con il secondo modello\n",
    "    results2 = model2(img, stream=True)\n",
    "    for r in results2:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls < len(classNames_model2):\n",
    "                class_name = classNames_model2[cls]\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = round(float(box.conf[0]) * 100, 2)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f'{class_name} {confidence}%', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Mostra l'immagine con le rilevazioni di entrambi i modelli\n",
    "    cv2.imshow(\"Detections with Two Models\", img)\n",
    "    \n",
    "    # Interruzione con ESC\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "# Libera le risorse\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per controllare la correttezza della targa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "plate_pattern = re.compile(r'^\\d{4}\\s[A-Z]{3}$')\n",
    "def validate(plate):  \n",
    "\n",
    "    if plate_pattern.match(plate):\n",
    "        \n",
    "        return plate\n",
    "    else:\n",
    "        \n",
    "        plate_refactored = re.sub(r'^\\s*.*?(\\d{4}\\s[A-Z]{3}).*$', r'\\1', plate)\n",
    "        return plate_refactored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "extracted_texts = []\n",
    "matriculas = []\n",
    "\n",
    "for plate_img in plates_images:\n",
    "\n",
    "    if plate_img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "        img_rgb = cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB)\n",
    "       \n",
    "       \n",
    "        # Preprocessing dell'immagine della targa per migliorare l'OCR \n",
    "        \n",
    "        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "        #filtered_img = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
    "        contrast_img = clahe.apply(gray)\n",
    "        resized_img = cv2.resize(contrast_img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "        kernel = np.array([[0, -2, 0], [-2, 9, -2], [0, -2, 0]])\n",
    "        sharpened_img = cv2.filter2D(resized_img, -1, kernel)\n",
    "\n",
    "        #Texto y localización en imagen de cada palabra\n",
    "        text = pytesseract.image_to_string(sharpened_img, config='--psm 8', output_type=Output.STRING)\n",
    "\n",
    "        text = validate(text)\n",
    "\n",
    "        if plate_pattern.match(text):\n",
    "            matriculas.append(text)\n",
    "            print(\"\\nMATRÍCULA DETECTADA:\", text)\n",
    "\n",
    "        cv2.imshow('img', sharpened_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = set()  # Insieme per tracciare elementi già visti\n",
    "\n",
    "for item in matriculas:\n",
    "    if item not in dup:\n",
    "        print(\"\\nMatricula: \", item)\n",
    "        dup.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from ultralytics import YOLO\n",
    "import csv\n",
    "\n",
    "# Configuración de Tesseract para OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Carga de modelos YOLO\n",
    "model1 = YOLO(\"C:/Users/danif/Downloads/best_vc.pt\")  # Modelo entrenado para matrículas\n",
    "model2 = YOLO('yolo11n.pt')  # Modelo para objetos comunes\n",
    "\n",
    "# Listas de clases para cada modelo\n",
    "classNames_model1 = [\"matricula\"]\n",
    "classNames_model2 = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Expresión regular para detectar matrículas en el formato correcto\n",
    "plate_pattern = re.compile(r'^\\d{4}\\s[A-Z]{3}$')\n",
    "\n",
    "# Ruta del video de entrada y salida\n",
    "input_video_path = \"C:/Users/danif/Downloads/C0142.MP4\"\n",
    "output_video_path = 'output_with_detections.mp4'\n",
    "\n",
    "# Configuración de captura de video y salida\n",
    "vid = cv2.VideoCapture(input_video_path)\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "# Archivo CSV para registrar los datos\n",
    "csv_file_path = 'detections.csv'\n",
    "csv_headers = ['frame', 'object_class', 'confidence', 'x1', 'y1', 'x2', 'y2', 'plate_text']\n",
    "\n",
    "# Inicializar listas de detecciones y OCR\n",
    "plates_images = []\n",
    "extracted_texts = []\n",
    "matriculas = []\n",
    "detected_data = []\n",
    "\n",
    "# Contadores acumulativos de personas y coches en todo el video\n",
    "person_count_total = 0\n",
    "car_count_total = 0\n",
    "\n",
    "# Iniciar la escritura en CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(csv_headers)\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, img = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Contadores de personas y coches por cada fotograma\n",
    "        person_count = 0\n",
    "        car_count = 0\n",
    "\n",
    "        # Detección de matrículas\n",
    "        results1 = model1(img, stream=True)\n",
    "        for r in results1:\n",
    "            for box in r.boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                if cls < len(classNames_model1):\n",
    "                    class_name = classNames_model1[cls]\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    confidence = round(float(box.conf[0]) * 100, 2)\n",
    "\n",
    "                    # Recortar la imagen de la matrícula\n",
    "                    plate_image = img[y1:y2, x1:x2]\n",
    "                    plates_images.append(plate_image)\n",
    "\n",
    "                    # Realizar OCR en la imagen de la matrícula\n",
    "                    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "                    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
    "                    contrast_img = clahe.apply(gray)\n",
    "                    resized_img = cv2.resize(contrast_img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "                    kernel = np.array([[0, -2, 0], [-2, 9, -2], [0, -2, 0]])\n",
    "                    sharpened_img = cv2.filter2D(resized_img, -1, kernel)\n",
    "                    text = pytesseract.image_to_string(sharpened_img, config='--psm 8', output_type=Output.STRING)\n",
    "                    text = re.sub(r'^\\s*.*?(\\d{4}\\s[A-Z]{3}).*$', r'\\1', text) if not plate_pattern.match(text) else text\n",
    "\n",
    "                    # Registro en CSV\n",
    "                    writer.writerow([frame_idx, class_name, confidence, x1, y1, x2, y2, text])\n",
    "\n",
    "                    # Visualización\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f'{class_name} {confidence}%', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "        # Detección de otros objetos\n",
    "        results2 = model2(img, stream=True)\n",
    "        for r in results2:\n",
    "            for box in r.boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                if cls < len(classNames_model2):\n",
    "                    class_name = classNames_model2[cls]\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    confidence = round(float(box.conf[0]) * 100, 2)\n",
    "\n",
    "                    # Incrementar contadores de personas y coches\n",
    "                    if class_name == \"person\":\n",
    "                        person_count += 1\n",
    "                        person_count_total += 1\n",
    "                    elif class_name == \"car\":\n",
    "                        car_count += 1\n",
    "                        car_count_total += 1\n",
    "\n",
    "                    # Dibujar las detecciones\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(img, f'{class_name} {confidence}%', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Mostrar conteos de personas y coches en la esquina superior izquierda\n",
    "        cv2.putText(img, f'Personas (Frame): {person_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(img, f'Coches (Frame): {car_count}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Mostrar conteos acumulativos en la esquina superior derecha\n",
    "        cv2.putText(img, f'Personas (Total): {person_count_total}', (frame_width - 300, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.putText(img, f'Coches (Total): {car_count_total}', (frame_width - 300, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "        # Mostrar el fotograma procesado en tiempo real\n",
    "        cv2.imshow(\"Detections with Two Models\", img)\n",
    "\n",
    "        # Escribir el fotograma procesado en el archivo de video de salida\n",
    "        out.write(img)\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Permite salir del bucle pulsando la tecla 'Esc'\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "# Liberar recursos\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
