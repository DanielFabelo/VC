{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73411e3",
   "metadata": {},
   "source": [
    "VERSIÓN ÚNICAMENTE CON DEEPFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "# Cargar las imágenes de superposición\n",
    "lipstick_image = cv2.imread('../P5/images/labiosrojos.png', cv2.IMREAD_UNCHANGED)\n",
    "mustache_image = cv2.imread('../P5/images/mostacho.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Verificar si las imágenes se han cargado correctamente\n",
    "if lipstick_image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen de labios.\")\n",
    "if mustache_image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen de bigote.\")\n",
    "\n",
    "# Convertir las imágenes a BGRA si no tienen canal alfa\n",
    "if lipstick_image is not None and lipstick_image.shape[2] == 3:\n",
    "    lipstick_image = cv2.cvtColor(lipstick_image, cv2.COLOR_BGR2BGRA)\n",
    "if mustache_image is not None and mustache_image.shape[2] == 3:\n",
    "    mustache_image = cv2.cvtColor(mustache_image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "def overlay_image(background, overlay, position):\n",
    "    x, y = position\n",
    "    h, w = overlay.shape[:2]\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "    for c in range(0, 3):  # Para cada canal de color\n",
    "        background[y:y+h, x:x+w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                       alpha_background * background[y:y+h, x:x+w, c])\n",
    "    return background\n",
    "\n",
    "# Iniciar la cámara\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "last_detection_time = 0  # Almacenamos el tiempo de la última detección\n",
    "detection_interval = 2.5  # Intervalo de tiempo en segundos para detección de género\n",
    "gender = None  # Inicializamos la variable de género\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    # realizar el análisis de género cada 2.5 segundos\n",
    "    if current_time - last_detection_time > detection_interval:\n",
    "        try:\n",
    "            # Análisis de género\n",
    "            obj = DeepFace.analyze(frame, actions=['gender'], enforce_detection=False)\n",
    "            gender = obj[0]['dominant_gender']\n",
    "            last_detection_time = current_time  # Actualizamos el tiempo de la última detección\n",
    "        except Exception as e:\n",
    "            print(\"Error de análisis:\", e)\n",
    "            continue\n",
    "\n",
    "    # Detección de rostros\n",
    "    faces = DeepFace.extract_faces(frame, detector_backend=\"retinaface\", align=False)\n",
    "    if len(faces) > 0 and 'facial_area' in faces[0]:\n",
    "        facial_area = faces[0]['facial_area']\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "\n",
    "        # Aplicar el filtro correspondiente según el género detectado\n",
    "        if gender == 'Man' and lipstick_image is not None:\n",
    "            overlay_img = cv2.resize(lipstick_image, (w, h // 2))\n",
    "            frame = overlay_image(frame, overlay_img, (x, y + h // 2))\n",
    "\n",
    "        elif gender == 'Woman' and mustache_image is not None:\n",
    "            overlay_img = cv2.resize(mustache_image, (w, h // 4))\n",
    "            frame = overlay_image(frame, overlay_img, (x, y + h // 2))\n",
    "\n",
    "    # Muestra el frame con la superposición\n",
    "    cv2.imshow(\"Filtro de Género\", frame)\n",
    "\n",
    "    # Esc para salir\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Cerrar cámara y ventanas\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93db340",
   "metadata": {},
   "source": [
    "VERSIÓN CON HAAR CASCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed6e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Cargar las imágenes de superposición\n",
    "lipstick_image = cv2.imread('../P5/images/labiosrojos.png', cv2.IMREAD_UNCHANGED)\n",
    "mustache_image = cv2.imread('../P5/images/mostacho.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Verificar si las imágenes se han cargado correctamente\n",
    "if lipstick_image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen de labios.\")\n",
    "if mustache_image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen de bigote.\")\n",
    "\n",
    "# Convertir las imágenes a BGRA si no tienen canal alfa\n",
    "if lipstick_image is not None and lipstick_image.shape[2] == 3:\n",
    "    lipstick_image = cv2.cvtColor(lipstick_image, cv2.COLOR_BGR2BGRA)\n",
    "if mustache_image is not None and mustache_image.shape[2] == 3:\n",
    "    mustache_image = cv2.cvtColor(mustache_image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "def overlay_image(background, overlay, position):\n",
    "    \"\"\"Superponer la imagen overlay sobre la imagen background en la posición indicada.\"\"\"\n",
    "    x, y = position\n",
    "    h, w = overlay.shape[:2]\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "\n",
    "    for c in range(0, 3):  # Para cada canal de color\n",
    "        background[y:y+h, x:x+w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                       alpha_background * background[y:y+h, x:x+w, c])\n",
    "    return background\n",
    "\n",
    "# Iniciar la cámara\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Inicializar variables para el análisis de género\n",
    "gender = None\n",
    "last_detection_time = 0\n",
    "detection_interval = 1.5  # Intervalo en segundos para detección de género\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Solo analizar el género cada 'detection_interval' segundos\n",
    "    if current_time - last_detection_time > detection_interval or gender is None:\n",
    "        try:\n",
    "            # Analizamos el género en una versión más pequeña del frame para acelerar el procesamiento\n",
    "            resized_frame = cv2.resize(frame, (640, 480))\n",
    "            obj = DeepFace.analyze(resized_frame, actions=['gender'], enforce_detection=False)\n",
    "            gender = obj[0]['dominant_gender']\n",
    "            last_detection_time = current_time\n",
    "        except Exception as e:\n",
    "            print(\"Error de análisis:\", e)\n",
    "            continue\n",
    "\n",
    "    # Usar Haar Cascade de OpenCV para detectar rostros rápidamente\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Aplicar el filtro correspondiente según el género detectado\n",
    "        if gender == 'Man' and lipstick_image is not None:\n",
    "            # Reducimos un poco el tamaño de los labios y bajamos su posición\n",
    "            overlay_img = cv2.resize(lipstick_image, (w // 2, h // 5))\n",
    "            frame = overlay_image(frame, overlay_img, (x + w // 4, y + int(h * 0.7)))\n",
    "        \n",
    "        elif gender == 'Woman' and mustache_image is not None:\n",
    "            # Ajustamos el tamaño y bajamos un poco el bigote\n",
    "            overlay_img = cv2.resize(mustache_image, (w // 2, h // 6))\n",
    "            frame = overlay_image(frame, overlay_img, (x + w // 4, y + int(h * 0.65)))\n",
    "\n",
    "    # Mostrar el frame con la superposición\n",
    "    cv2.imshow(\"Filtro de Genero\", frame)\n",
    "\n",
    "    # Salir con 'ESC'\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Cerrar cámara y ventanas\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fa090",
   "metadata": {},
   "source": [
    "VERSIÓN CON MEDIAPIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec93730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Cargar imagen de bigote\n",
    "mustache_image = cv2.imread('../P5/images/mostacho.png', cv2.IMREAD_UNCHANGED)\n",
    "if mustache_image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen de bigote.\")\n",
    "\n",
    "if mustache_image is not None and mustache_image.shape[2] == 3:\n",
    "    mustache_image = cv2.cvtColor(mustache_image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "# Función para superponer la imagen del bigote\n",
    "def overlay_image(background, overlay, position):\n",
    "    x, y = position\n",
    "    h, w = overlay.shape[:2]\n",
    "    bh, bw = background.shape[:2]\n",
    "\n",
    "    # Verificar límites\n",
    "    if x >= bw or y >= bh:\n",
    "        return background  # Si está completamente fuera de la imagen, no hacer nada\n",
    "\n",
    "    # Ajustar la región si se sale de los límites\n",
    "    w = min(w, bw - x)\n",
    "    h = min(h, bh - y)\n",
    "    overlay = overlay[:h, :w]\n",
    "\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        background[y:y+h, x:x+w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                       alpha_background * background[y:y+h, x:x+w, c])\n",
    "    return background\n",
    "\n",
    "# Configuración de Mediapipe para detección y mapeo de landmarks faciales\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Captura de video\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "gender = None\n",
    "last_detection_time = 0\n",
    "detection_interval = 2\n",
    "\n",
    "# Iniciar el modelo de detección de rostros y landmarks\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detectar género a intervalos\n",
    "        current_time = time.time()\n",
    "        if current_time - last_detection_time > detection_interval or gender is None:\n",
    "            try:\n",
    "                resized_frame = cv2.resize(frame, (640, 480))\n",
    "                obj = DeepFace.analyze(resized_frame, actions=['gender'], enforce_detection=False)\n",
    "                gender = obj[0]['dominant_gender']\n",
    "                last_detection_time = current_time\n",
    "            except Exception as e:\n",
    "                print(\"Error de análisis:\", e)\n",
    "                continue\n",
    "\n",
    "        # Procesar landmarks faciales con Mediapipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                ih, iw, _ = frame.shape\n",
    "\n",
    "                if gender == 'Man':\n",
    "                    # Puntos alrededor de ambos labios (superior e inferior)\n",
    "                    lip_points = [\n",
    "                        61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, \n",
    "                        324, 318, 402, 317, 14, 87, 178,  95, 88, 178, 191, 80,\n",
    "                        81, 82, 13, 312, 311, 310, 415, 308\n",
    "                    ]\n",
    "                    lip_coords = [(int(face_landmarks.landmark[point].x * iw), int(face_landmarks.landmark[point].y * ih)) for point in lip_points]\n",
    "\n",
    "                    # Crear una máscara roja sobre los labios\n",
    "                    lip_mask = np.zeros_like(frame)\n",
    "                    cv2.fillPoly(lip_mask, [np.array(lip_coords, np.int32)], (0, 0, 255))\n",
    "                    frame = cv2.addWeighted(frame, 1, lip_mask, 0.4, 0)\n",
    "\n",
    "                elif gender == 'Woman' and mustache_image is not None:\n",
    "                    # Obtener puntos clave para colocar el bigote\n",
    "                    left_mouth_corner = face_landmarks.landmark[78]\n",
    "                    right_mouth_corner = face_landmarks.landmark[308]\n",
    "\n",
    "                    # Calcular posición y tamaño del bigote\n",
    "                    x1, y1 = int(left_mouth_corner.x * iw), int(left_mouth_corner.y * ih)\n",
    "                    x2, y2 = int(right_mouth_corner.x * iw), int(right_mouth_corner.y * ih)\n",
    "\n",
    "                    # Calcular ancho del bigote y posicionarlo\n",
    "                    mustache_width = x2 - x1\n",
    "                    mustache_height = int(mustache_width * mustache_image.shape[0] / mustache_image.shape[1])\n",
    "                    overlay_img = cv2.resize(mustache_image, (mustache_width, mustache_height))\n",
    "\n",
    "                    # Posicionar bigote ligeramente por encima del centro de la boca\n",
    "                    y_offset = int(y1 - mustache_height / 2)\n",
    "                    frame = overlay_image(frame, overlay_img, (x1, y_offset))\n",
    "\n",
    "        # Mostrar el video con los filtros aplicados\n",
    "        cv2.imshow(\"Filtro de Genero\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
