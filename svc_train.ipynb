{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código sin landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils  # Opcional, para dibujar los landmarks (depuración)\n",
    "\n",
    "# Ruta del dataset (ajústala según tu estructura)\n",
    "dataset_dir = '..\\\\ASL\\\\asl_dataset\\\\'  # Cambia esto a la ruta de tu dataset\n",
    "letters = sorted(os.listdir(dataset_dir))  # Lista de carpetas por letra\n",
    "\n",
    "# Lista para almacenar los datos procesados\n",
    "data = []\n",
    "\n",
    "# Procesar cada carpeta (letra) y las imágenes dentro de ella\n",
    "for letter in letters:\n",
    "    letter_dir = os.path.join(dataset_dir, letter)\n",
    "    \n",
    "    # Verificar que sea un directorio válido\n",
    "    if not os.path.isdir(letter_dir):\n",
    "        print(f\"Advertencia: {letter_dir} no es un directorio válido. Saltando...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Procesando letra: {letter}\")  # Depuración: letra actual\n",
    "\n",
    "    for image_file in os.listdir(letter_dir):\n",
    "        image_path = os.path.join(letter_dir, image_file)\n",
    "        print(f\"Procesando imagen: {image_path}\")  # Depuración: imagen actual\n",
    "        \n",
    "        # Leer la imagen\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: No se pudo leer la imagen {image_path}. Saltando...\")\n",
    "            continue\n",
    "        \n",
    "        # Convertir la imagen a RGB (requerido por Mediapipe)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesar la imagen con Mediapipe\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        # Si se detectan landmarks, extraerlos\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            \n",
    "            # Extraer coordenadas (x, y, z) de los landmarks\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.append([lm.x, lm.y, lm.z])\n",
    "            landmarks_flatten = np.array(landmarks).flatten()  # Aplanar los datos\n",
    "            \n",
    "            # Guardar los landmarks y la etiqueta (letra)\n",
    "            data.append(landmarks_flatten.tolist() + [letter])\n",
    "        else:\n",
    "            print(f\"Advertencia: No se detectaron landmarks en {image_path}. Saltando...\")\n",
    "\n",
    "# Cerrar Mediapipe\n",
    "hands.close()\n",
    "\n",
    "# Crear el DataFrame y guardar como CSV\n",
    "columns = [f\"x{i}\" for i in range(63)] + [\"label\"]  # 63 coordenadas (x, y, z) + etiqueta\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Guardar el CSV\n",
    "output_csv = \"asl_landmarks.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Dataset procesado guardado en {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['asl_model.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset procesado\n",
    "data = pd.read_csv('asl_landmarks.csv')\n",
    "\n",
    "# Separar las características (X) y las etiquetas (y)\n",
    "X = data.iloc[:, :-1].values  # Coordenadas de los landmarks\n",
    "y = data.iloc[:, -1].values   # Etiquetas (letras)\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo SVM\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Guardar el modelo entrenado para su uso posterior\n",
    "import joblib\n",
    "joblib.dump(model, \"svm_asl_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
